{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Translation Guide Generator\n",
        "\n",
        "In case you want to experiment with my main post-processing step without having to scroll through my mess of a source code document, here's a tool to help you use it here!\n",
        "\n",
        "**Scroll to the bottom to get started on generation!**"
      ],
      "metadata": {
        "id": "7I4R7op0S3y9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Anh91LRGSsS6",
        "outputId": "1c704e8f-2be9-4c35-de7d-4fdef8c9ef61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "def get_parts_of_speech_nltk(sentence):\n",
        "  words = nltk.word_tokenize(sentence)\n",
        "  pos_tags = nltk.pos_tag(words)\n",
        "  return pos_tags\n",
        "\n",
        "\n",
        "def format_pos(pos_list):\n",
        "  #Creating an empty dictionary with keys for parts of speech\n",
        "  my_dict = {\n",
        "      \"subjects\": [],\n",
        "      \"objects\": [],\n",
        "      \"verbs\": [],\n",
        "      \"adjectives\": [],\n",
        "      \"adverbs\": [],\n",
        "      \"others\": []\n",
        "  }\n",
        "\n",
        "  #Declaring lists for the nltk tags\n",
        "  nouns = [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\n",
        "  verbs = [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]\n",
        "  adjectives = [\"JJ\", \"JJR\", \"JJS\"]\n",
        "  adverbs = [\"RB\", \"RBR\", \"RBS\"]\n",
        "  pronouns = [\"PRP\", \"PRP$\", \"WP\", \"WP$\"]\n",
        "  prepositions = [\"IN\"]\n",
        "\n",
        "  #Now we iterate through and add to the dictionary!\n",
        "  for item in pos_list:\n",
        "    if item[1] in nouns:\n",
        "      if my_dict[\"subjects\"] == []:\n",
        "        my_dict[\"subjects\"].append(item[0])\n",
        "      else:\n",
        "        my_dict[\"objects\"].append(item[0])\n",
        "    elif item[1] in verbs:\n",
        "      my_dict[\"verbs\"].append(item[0])\n",
        "    elif item[1] in adjectives:\n",
        "      my_dict[\"adjectives\"].append(item[0])\n",
        "    elif item[1] in adverbs:\n",
        "      my_dict[\"adverbs\"].append(item[0])\n",
        "    else:\n",
        "      my_dict[\"others\"].append(item[0])\n",
        "\n",
        "  return my_dict\n",
        "\n",
        "def build_translation_guide(english_text, pos_dict):\n",
        "  subjects = pos_dict[\"subjects\"][0]\n",
        "  objects = \"\"\n",
        "  verbs = \"\"\n",
        "  adjectives = \"\"\n",
        "  adverbs = \"\"\n",
        "  others = \"\"\n",
        "\n",
        "  for obj in pos_dict[\"objects\"]:\n",
        "    objects += obj + \", \"\n",
        "  for verb in pos_dict[\"verbs\"]:\n",
        "    verbs += verb + \", \"\n",
        "  for adj in pos_dict[\"adjectives\"]:\n",
        "    adjectives += adj + \", \"\n",
        "  for adv in pos_dict[\"adverbs\"]:\n",
        "    adverbs += adv + \", \"\n",
        "  for other in pos_dict[\"others\"]:\n",
        "    others += other + \", \"\n",
        "\n",
        "\n",
        "  print(\"--------------------------------------\")\n",
        "  print(\"English text: \" + english_text)\n",
        "  print(\"Subjects: \" + subjects)\n",
        "  print(\"Objects: \" + objects)\n",
        "  print(\"Verbs: \" + verbs)\n",
        "  print(\"Adjectives: \" + adjectives)\n",
        "  print(\"Adverbs: \" + adverbs)\n",
        "  print(\"Other words: \" + others)\n",
        "  print(\"--------------------------------------\")\n",
        "\n",
        "def format_translation(english_text):\n",
        "  pos_dict = format_pos(get_parts_of_speech_nltk(english_text))\n",
        "  build_translation_guide(english_text, pos_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Down here!\n",
        "Replace the placeholder string with an english sentence to get a translation guide! If you want, you can pull text you got from a MT model to replicate the full effect!"
      ],
      "metadata": {
        "id": "ebWlpndYTgy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "your_text = \"REPLACE ME!\"\n",
        "\n",
        "format_translation(your_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9g8OYo9T_au",
        "outputId": "4f7373e6-0757-46f5-c59f-474c5de0d278"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------\n",
            "English text: REPLACE ME!\n",
            "Subjects: ME\n",
            "Objects: \n",
            "Verbs: REPLACE, \n",
            "Adjectives: \n",
            "Adverbs: \n",
            "Other words: !, \n",
            "--------------------------------------\n"
          ]
        }
      ]
    }
  ]
}